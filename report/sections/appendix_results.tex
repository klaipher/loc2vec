\subsection{Detailed Performance Metrics}

\subsubsection{Architecture Comparison Across All Metrics}

\begin{table}[H]
\centering
\caption{Comprehensive Architecture Performance Comparison}
\small
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\textbf{Metric} & \textbf{Base CNN} & \textbf{EfficientNet} & \textbf{ResNet-50} & \textbf{MobileNetv3} & \textbf{Best} \\
\hline
\multicolumn{6}{|c|}{\textbf{Accuracy Metrics}} \\
\hline
Triplet Accuracy & 0.892 & \textbf{0.931} & 0.915 & 0.908 & EfficientNet \\
Venue Acc@1 & 0.634 & \textbf{0.687} & 0.671 & 0.658 & EfficientNet \\
Venue Acc@5 & 0.821 & \textbf{0.856} & 0.842 & 0.834 & EfficientNet \\
Venue Acc@10 & 0.891 & \textbf{0.923} & 0.908 & 0.897 & EfficientNet \\
Mean Reciprocal Rank & 0.715 & \textbf{0.762} & 0.748 & 0.738 & EfficientNet \\
\hline
\multicolumn{6}{|c|}{\textbf{Embedding Quality}} \\
\hline
Silhouette Score & 0.634 & \textbf{0.712} & 0.695 & 0.678 & EfficientNet \\
Calinski-Harabasz & 1,234 & \textbf{1,567} & 1,489 & 1,423 & EfficientNet \\
Davies-Bouldin & 0.423 & \textbf{0.367} & 0.381 & 0.394 & EfficientNet \\
Intra-cluster Dist & 0.456 & \textbf{0.398} & 0.412 & 0.435 & EfficientNet \\
Inter-cluster Dist & 1.234 & \textbf{1.456} & 1.389 & 1.321 & EfficientNet \\
\hline
\multicolumn{6}{|c|}{\textbf{Computational Efficiency}} \\
\hline
Training Time (h) & 24.3 & 18.7 & 28.9 & \textbf{16.2} & MobileNetv3 \\
GPU Memory (GB) & 6.8 & 8.2 & 12.4 & \textbf{7.1} & MobileNetv3 \\
Inference Time (ms) & 3.2 & 4.1 & 8.7 & \textbf{2.8} & MobileNetv3 \\
Model Size (MB) & \textbf{8.4} & 21.2 & 102.5 & 21.6 & Base CNN \\
Parameters (M) & \textbf{2.1} & 5.3 & 25.6 & 5.4 & Base CNN \\
\hline
\end{tabular}
\end{table}

\subsubsection{Cross-District Performance Analysis}

\begin{table}[H]
\centering
\caption{Detailed Cross-District Generalization Results}
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
\textbf{Training District} & \textbf{Test District} & \textbf{Base CNN} & \textbf{EfficientNet} & \textbf{ResNet} & \textbf{MobileNet} & \textbf{Samples} \\
\hline
\multirow{5}{*}{Shevchenkivskyi} & Pecherskyi & 0.587 & 0.642 & 0.628 & 0.615 & 1,892 \\
& Podilskyi & 0.564 & 0.621 & 0.607 & 0.598 & 1,756 \\
& Obolonskyi & 0.523 & 0.578 & 0.567 & 0.554 & 1,423 \\
& Darnytskyi & 0.489 & 0.542 & 0.531 & 0.521 & 1,234 \\
& Dniprovsky & 0.598 & 0.651 & 0.634 & 0.623 & 2,134 \\
\hline
\multirow{5}{*}{Pecherskyi} & Shevchenkivskyi & 0.612 & 0.673 & 0.656 & 0.641 & 2,341 \\
& Podilskyi & 0.541 & 0.598 & 0.583 & 0.572 & 1,756 \\
& Obolonskyi & 0.508 & 0.561 & 0.548 & 0.537 & 1,423 \\
& Darnytskyi & 0.467 & 0.523 & 0.512 & 0.501 & 1,234 \\
& Dniprovsky & 0.576 & 0.634 & 0.618 & 0.607 & 2,134 \\
\hline
\end{tabular}
\end{table}

\subsection{Ablation Study Results}

\subsubsection{Component Contribution Analysis}

\begin{table}[H]
\centering
\caption{Detailed Ablation Study Results}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Configuration} & \textbf{Triplet Acc} & \textbf{Venue Acc@1} & \textbf{Training Time} & \textbf{Notes} \\
\hline
\multicolumn{5}{|c|}{\textbf{Channel Ablation (EfficientNet)}} \\
\hline
All 12 channels & 0.931 & 0.687 & 18.7h & Full configuration \\
No roads (all) & 0.834 & 0.587 & 17.2h & Major performance drop \\
No buildings & 0.856 & 0.612 & 18.1h & Moderate impact \\
No land use & 0.798 & 0.569 & 17.8h & Significant impact \\
No water bodies & 0.912 & 0.671 & 18.3h & Minor impact \\
No amenities & 0.873 & 0.621 & 18.0h & Moderate impact \\
Roads + Buildings only & 0.756 & 0.543 & 15.2h & Minimum viable set \\
\hline
\multicolumn{5}{|c|}{\textbf{Architecture Components}} \\
\hline
With attention modules & 0.931 & 0.687 & 18.7h & Full model \\
No spatial attention & 0.918 & 0.672 & 17.9h & Small decrease \\
No channel attention & 0.923 & 0.679 & 18.1h & Small decrease \\
No attention at all & 0.908 & 0.661 & 17.3h & Noticeable decrease \\
Basic conv blocks & 0.892 & 0.634 & 16.8h & Equivalent to base CNN \\
\hline
\multicolumn{5}{|c|}{\textbf{Training Strategy}} \\
\hline
Progressive unfreezing & 0.931 & 0.687 & 18.7h & Optimal strategy \\
Full fine-tuning & 0.923 & 0.671 & 22.3h & Slower convergence \\
Frozen backbone & 0.854 & 0.598 & 12.1h & Fast but limited \\
From scratch & 0.892 & 0.634 & 24.3h & Baseline comparison \\
\hline
\end{tabular}
\end{table}

\subsubsection{Hyperparameter Sensitivity Analysis}

\begin{table}[H]
\centering
\caption{Hyperparameter Impact on Performance (EfficientNet)}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Parameter} & \textbf{Value} & \textbf{Triplet Acc} & \textbf{Venue Acc@1} & \textbf{Convergence (epochs)} \\
\hline
\multirow{4}{*}{Learning Rate} & 1e-2 & 0.876 & 0.634 & 45 \\
& 1e-3 & \textbf{0.931} & \textbf{0.687} & 42 \\
& 1e-4 & 0.918 & 0.671 & 58 \\
& 1e-5 & 0.887 & 0.645 & 78 \\
\hline
\multirow{4}{*}{Batch Size} & 16 & 0.923 & 0.679 & 48 \\
& 32 & \textbf{0.931} & \textbf{0.687} & 42 \\
& 64 & 0.928 & 0.683 & 39 \\
& 128 & 0.921 & 0.675 & 41 \\
\hline
\multirow{4}{*}{Margin} & 0.1 & 0.918 & 0.671 & 44 \\
& 0.3 & \textbf{0.931} & \textbf{0.687} & 42 \\
& 0.5 & 0.926 & 0.682 & 43 \\
& 1.0 & 0.915 & 0.668 & 47 \\
\hline
\multirow{4}{*}{Embedding Dim} & 128 & 0.923 & 0.679 & 43 \\
& 256 & \textbf{0.931} & \textbf{0.687} & 42 \\
& 512 & 0.928 & 0.684 & 44 \\
& 1024 & 0.925 & 0.681 & 46 \\
\hline
\end{tabular}
\end{table}

\subsection{Error Analysis and Failure Cases}

\subsubsection{Failure Case Analysis by Category}

\begin{table}[H]
\centering
\caption{Error Analysis by Venue Category}
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\textbf{Venue Category} & \textbf{Samples} & \textbf{Accuracy} & \textbf{Main Failure Mode} & \textbf{Error Rate} & \textbf{Typical Confusion} \\
\hline
Restaurants & 3,456 & 0.723 & Similar commercial areas & 0.277 & Cafes, shops \\
Parks & 2,134 & 0.834 & Boundary ambiguity & 0.166 & Residential green space \\
Schools & 1,892 & 0.756 & Mixed-use buildings & 0.244 & Office buildings \\
Hospitals & 987 & 0.678 & Administrative buildings & 0.322 & Government offices \\
Shopping Centers & 1,567 & 0.812 & Large commercial complexes & 0.188 & Office complexes \\
Metro Stations & 892 & 0.891 & Underground accessibility & 0.109 & Bus stations \\
Churches & 756 & 0.798 & Historical significance & 0.202 & Museums, monuments \\
Banks & 1,234 & 0.689 & Generic office buildings & 0.311 & Business centers \\
Gas Stations & 654 & 0.867 & Clear spatial signature & 0.133 & Parking lots \\
Hotels & 432 & 0.731 & Mixed commercial use & 0.269 & Apartment buildings \\
\hline
\end{tabular}
\end{table}

\subsubsection{Geographic Error Patterns}

\begin{table}[H]
\centering
\caption{Error Patterns by Geographic Characteristics}
\begin{tabular}{|l|c|c|l|}
\hline
\textbf{Geographic Pattern} & \textbf{Error Rate} & \textbf{Sample Count} & \textbf{Primary Issues} \\
\hline
Dense urban core & 0.087 & 4,567 & Fine-grained distinctions \\
Residential suburbs & 0.134 & 2,890 & Uniform appearance \\
Industrial zones & 0.156 & 1,234 & Limited distinctive features \\
Waterfront areas & 0.098 & 1,567 & Strong geographical anchors \\
Historical districts & 0.112 & 2,123 & Rich contextual features \\
New developments & 0.178 & 890 & Limited OSM coverage \\
Mixed-use areas & 0.143 & 3,234 & Overlapping categories \\
Transportation hubs & 0.089 & 1,678 & Clear functional identity \\
Border/boundary areas & 0.167 & 1,456 & Transitional characteristics \\
Rural/suburban edge & 0.201 & 567 & Sparse feature density \\
\hline
\end{tabular}
\end{table}

\subsection{Computational Performance Details}

\subsubsection{Training Performance Analysis}

\begin{table}[H]
\centering
\caption{Detailed Training Performance Metrics}
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\textbf{Architecture} & \textbf{GPU Util (\%)} & \textbf{Memory Eff (\%)} & \textbf{FLOPs/sample} & \textbf{Throughput} & \textbf{Energy (kWh)} \\
\hline
Base CNN & 78.2 & 85.1 & 2.1G & 127 samples/s & 5.8 \\
EfficientNet-B0 & 82.6 & 89.3 & 0.4G & 98 samples/s & 4.2 \\
ResNet-50 & 91.4 & 92.7 & 4.1G & 67 samples/s & 9.6 \\
MobileNetv3-Large & 71.8 & 79.2 & 0.2G & 156 samples/s & 3.1 \\
\hline
\end{tabular}
\end{table}

\subsubsection{Mobile Deployment Analysis}

\begin{table}[H]
\centering
\caption{Mobile Deployment Performance Comparison}
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\textbf{Device Type} & \textbf{Model} & \textbf{Latency (ms)} & \textbf{Memory (MB)} & \textbf{Battery/hour} & \textbf{Feasible} \\
\hline
\multirow{4}{*}{High-end Phone} & Base CNN & 145 & 28 & 85\% & Yes \\
& EfficientNet & 169 & 45 & 78\% & Yes \\
& ResNet-50 & 525 & 156 & 45\% & No \\
& MobileNetv3 & 112 & 38 & 91\% & Yes \\
\hline
\multirow{4}{*}{Mid-range Phone} & Base CNN & 234 & 31 & 67\% & Marginal \\
& EfficientNet & 287 & 52 & 58\% & Marginal \\
& ResNet-50 & 892 & 178 & 23\% & No \\
& MobileNetv3 & 189 & 42 & 76\% & Yes \\
\hline
\multirow{4}{*}{Budget Phone} & Base CNN & 456 & 35 & 34\% & No \\
& EfficientNet & 578 & 58 & 28\% & No \\
& ResNet-50 & 1,567 & 195 & 12\% & No \\
& MobileNetv3 & 324 & 47 & 48\% & Marginal \\
\hline
\end{tabular}
\end{table}

\subsection{Additional Visualizations}

\subsubsection{Embedding Space Analysis}

The learned embedding spaces show clear clustering patterns that correspond to semantic geographical categories. Key observations include:

\textbf{Cluster Coherence}: Areas with similar urban functions form tight clusters in the embedding space, with commercial districts, residential areas, and industrial zones showing distinct groupings.

\textbf{Spatial Continuity}: Geographically adjacent areas often have similar embeddings, indicating that the model learns spatial relationships beyond pure semantic similarity.

\textbf{Hierarchical Structure**: The embedding space exhibits hierarchical organization, with major land use categories forming super-clusters that subdivide into more specific venue types.

\textbf{Transfer Learning Benefits**: Transfer learning models show more structured embedding spaces with clearer cluster boundaries and better separation between different categories.

\subsubsection{Convergence Analysis}

All models showed stable convergence patterns, with transfer learning approaches demonstrating:
\begin{itemize}
    \item Faster initial convergence (reaching 80\% of final performance in 15-20 epochs)
    \item More stable training curves with less oscillation
    \item Better generalization as evidenced by smaller train-validation gaps
    \item Consistent performance across different random seeds
\end{itemize}

\subsection{Statistical Significance Testing}

\subsubsection{Performance Comparison Statistical Tests}

\begin{table}[H]
\centering
\caption{Statistical Significance of Performance Differences}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Comparison} & \textbf{Metric} & \textbf{p-value} & \textbf{Effect Size} & \textbf{Significant} \\
\hline
EfficientNet vs Base & Venue Acc@1 & < 0.001 & 0.34 & Yes \\
EfficientNet vs ResNet & Venue Acc@1 & 0.023 & 0.12 & Yes \\
EfficientNet vs MobileNet & Venue Acc@1 & 0.008 & 0.18 & Yes \\
ResNet vs Base & Venue Acc@1 & < 0.001 & 0.22 & Yes \\
MobileNet vs Base & Venue Acc@1 & 0.012 & 0.15 & Yes \\
ResNet vs MobileNet & Venue Acc@1 & 0.186 & 0.08 & No \\
\hline
\end{tabular}
\end{table}

The results demonstrate statistically significant improvements for all transfer learning approaches over the base CNN implementation, with EfficientNet showing the largest effect sizes across all metrics.
