\section{Results}
\label{sec:results}

This section presents our experimental results, including quantitative performance metrics, qualitative analysis of learned embeddings, and comparative evaluation of different architectural approaches.

\subsection{Model Performance Comparison}

\subsubsection{Training Convergence}

All three architectures managed to converge during training, but each had its own personality. EfficientNet-B0 was the most well-behaved - it trained smoothly with steady loss decrease and reached its best performance after about 60 epochs without much overfitting. It was like the reliable student who consistently does well.

ResNet-18 was more of a sprinter - it showed really fast initial progress but became a bit unstable later on. We had to be careful with learning rate scheduling to prevent it from oscillating too much in the later epochs. The residual connections definitely helped with training stability overall though.

MobileNetV3-Small was the efficiency champion. It reached good performance in just 40 epochs, making it perfect for situations where you need to train quickly or don't have tons of computational resources. It was surprisingly effective for such a small model.

\subsubsection{Quantitative Results}

\begin{table}[H]
\centering
\caption{Performance comparison of different architectures on Kyiv location embedding task}
\label{tab:performance}
\begin{tabular}{lccccc}
\toprule
\textbf{Architecture} & \textbf{Triplet Acc.} & \textbf{Silhouette} & \textbf{Recall@5} & \textbf{Training Time} & \textbf{Params (M)} \\
\midrule
EfficientNet-B0 & \textbf{87.3\%} & \textbf{0.64} & \textbf{0.82} & 4.2h & 5.3 \\
ResNet-18 & 84.7\% & 0.61 & 0.79 & 3.8h & 11.2 \\
ResNet-34 & 86.1\% & 0.62 & 0.80 & 6.1h & 21.3 \\
MobileNetV3-Small & 81.2\% & 0.58 & 0.75 & \textbf{2.9h} & \textbf{2.5} \\
Baseline (Original) & 79.8\% & 0.55 & 0.71 & 5.5h & 8.7 \\
\bottomrule
\end{tabular}
\end{table}

EfficientNet-B0 achieved the best overall performance across all metrics, demonstrating superior embedding quality while maintaining reasonable computational efficiency. The compound scaling approach effectively balanced model capacity with computational requirements.

\subsubsection{Transfer Learning Impact}

Using transfer learning made a huge difference compared to training from scratch. We saw about 40\% faster convergence when starting with pre-trained weights, and got 8-12\% better triplet accuracy across all our architectures. The training was also much more stable - less variance in the training curves and more consistent results between different runs. This was especially helpful when we had limited training data, where transfer learning really shines.

The progressive unfreezing strategy we used turned out to be particularly smart. Instead of fine-tuning everything at once, we gradually allowed the models to adapt their pre-trained features to our spatial domain while keeping the useful low-level representations they had learned from ImageNet. It's like slowly adjusting to a new environment rather than jumping in completely unprepared.

\subsection{Embedding Quality Analysis}

\subsubsection{Spatial Coherence}

Our analysis revealed strong spatial coherence in the learned embeddings:

\textbf{Geographic Consistency:} The correlation between embedding distance and geographic distance showed values of 0.73-0.81 across different models, indicating that the embeddings successfully preserve spatial relationships.

\textbf{Neighborhood Preservation:} Local neighborhood structures were well-maintained in the embedding space, with 85-90\% of nearest neighbors in embedding space being geographically proximate.

\textbf{Scale Invariance:} The embeddings demonstrated robustness across different spatial scales, from local street-level patterns to district-wide characteristics.

\subsubsection{Semantic Clustering}

The learned embeddings successfully captured semantic similarities:

\textbf{Land Use Separation:} Clear clustering of different land use types:
\begin{itemize}
    \item Residential areas formed coherent clusters with subclusters for different housing types
    \item Commercial districts grouped together despite geographic separation
    \item Industrial zones created distinct clusters away from residential areas
    \item Parks and green spaces formed semantically coherent groups
\end{itemize}

\textbf{Urban Structure Understanding:} The embeddings captured various urban structures:
\begin{itemize}
    \item City center locations clustered together, reflecting high-density commercial areas
    \item Soviet-era housing districts formed distinct groups based on architectural similarity
    \item Modern residential developments were distinguishable from older neighborhoods
    \item Transportation hubs (metro stations, bus terminals) formed identifiable clusters
\end{itemize}

\subsection{Qualitative Analysis}

\subsubsection{Visualization Results}

t-SNE and UMAP projections revealed meaningful structure in the embedding space:

\textbf{Clear Semantic Groupings:} The 2D projections showed distinct clusters corresponding to different types of urban areas, with smooth transitions between related categories.

\textbf{Hierarchical Structure:} The embeddings captured hierarchical relationships, with fine-grained distinctions within broader categories (e.g., different types of residential areas within the broader residential cluster).

\textbf{Geographic Coherence:} Areas that are geographically connected often appeared as connected regions in the embedding visualization, suggesting the model learned meaningful spatial relationships.

\subsubsection{Case Studies}

\textbf{Maidan Nezalezhnosti (Independence Square):}
The city center location showed high similarity to other major squares and commercial centers while being distinct from residential areas. The embedding successfully captured its role as a central public space.

\textbf{Troieshchyna District:}
This large Soviet-era residential district formed a coherent cluster in embedding space, with internal variations corresponding to different microdistricts and their specific characteristics.

\textbf{Hydropark:}
The recreational island area showed similarity to other parks and green spaces while maintaining distinctiveness due to its unique island geography and recreational facilities.

\subsection{Ablation Studies}

\subsubsection{Channel Importance Analysis}

We conducted ablation studies by removing different channel combinations:

\begin{itemize}
    \item \textbf{Road Networks (Channels 1-3):} Removing road information caused a 15\% drop in performance, highlighting their importance for urban structure understanding
    \item \textbf{Building Information (Channels 4-6):} Building data removal led to 12\% performance decrease, showing its significance for semantic differentiation
    \item \textbf{Natural Features (Channels 7-8):} Less critical for overall performance (6\% decrease) but important for specific area types
    \item \textbf{Transportation (Channel 9):} Moderate impact (8\% decrease) with higher importance in central areas
\end{itemize}

\subsubsection{Augmentation Impact}

Different augmentation strategies showed varying benefits:

\begin{itemize}
    \item \textbf{Geometric Augmentation:} Essential for orientation invariance (20\% improvement)
    \item \textbf{Channel Dropout:} Improved robustness to missing data (8\% improvement)
    \item \textbf{Noise Addition:} Helped with GPS uncertainty simulation (5\% improvement)
    \item \textbf{Seasonal Variation:} Modest but consistent improvements (3\% improvement)
\end{itemize}

\subsection{Computational Efficiency Analysis}

\subsubsection{Training Efficiency}

\begin{itemize}
    \item \textbf{Memory Usage:} EfficientNet required 8GB VRAM, ResNet variants needed 6-10GB, MobileNetV3 used only 4GB
    \item \textbf{Training Speed:} MobileNetV3 was fastest (2.9h), followed by ResNet-18 (3.8h) and EfficientNet (4.2h)
    \item \textbf{Energy Consumption:} MobileNetV3 showed 45\% lower energy consumption compared to larger models
\end{itemize}

\subsubsection{Inference Performance}

For practical deployment considerations:

\begin{itemize}
    \item \textbf{Latency:} MobileNetV3 achieved 12ms inference time, EfficientNet 28ms, ResNet-34 35ms
    \item \textbf{Throughput:} MobileNetV3 processed 850 locations/second, EfficientNet 420/second
    \item \textbf{Model Size:} MobileNetV3 (10MB), EfficientNet (21MB), ResNet-34 (83MB)
\end{itemize}

\subsection{Error Analysis}

\subsubsection{Common Failure Cases}

Analysis of incorrect predictions revealed several patterns:

\textbf{Transition Areas:} Locations at boundaries between different land use types were often misclassified, suggesting the need for better handling of mixed-use areas.

\textbf{Sparse Data Regions:} Areas with limited OSM coverage showed lower embedding quality, highlighting the importance of data completeness.

\textbf{Unique Locations:} Highly distinctive locations (airports, large stadiums) sometimes showed unexpected similarities to semantically different but structurally similar areas.

\subsubsection{Model Limitations}

Several limitations were identified:

\begin{itemize}
    \item \textbf{Temporal Invariance:} The model cannot account for time-dependent changes in location characteristics
    \item \textbf{Cultural Context:} Some culturally specific urban patterns may not be captured effectively
    \item \textbf{Scale Sensitivity:} Performance varies with the spatial scale of analysis
    \item \textbf{Data Dependency:} Heavy reliance on OSM data quality and completeness
\end{itemize}

\subsection{Validation on Real-world Tasks}

To validate the practical utility of our embeddings, we tested them on downstream tasks:

\subsubsection{Venue Type Prediction}

Using the learned embeddings as features for venue type classification:
\begin{itemize}
    \item Achieved 78\% accuracy on a held-out test set of labeled venues
    \item Significantly outperformed coordinate-based baselines (62\% accuracy)
    \item Showed good generalization across different districts of Kyiv
\end{itemize}

\subsubsection{Similar Location Retrieval}

For location recommendation and similarity search:
\begin{itemize}
    \item 85\% user satisfaction in qualitative evaluation of similar location suggestions
    \item Effective discovery of semantically similar locations across the city
    \item Useful for urban planning and business location analysis applications
\end{itemize}

The results demonstrate that our approach successfully adapts the Loc2Vec methodology to Kyiv city, with modern architectures and transfer learning providing significant improvements over baseline approaches.
